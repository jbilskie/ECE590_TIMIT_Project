{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<timit_utils.core.SubCorpus at 0x20f28ad0e10>,\n",
       " <timit_utils.core.SubCorpus at 0x20f302cbda0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n",
    "import timit_utils as tu\n",
    "import timit_utils.audio_utils as au\n",
    "import timit_utils.drawing_utils as du\n",
    "import librosa\n",
    "import pywt\n",
    "import random\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "from scipy.signal import butter, lfilter, sosfilt\n",
    "\n",
    "corpus = tu.Corpus('TIMIT')\n",
    "train = corpus.train\n",
    "test = corpus.test\n",
    "corpus.train, corpus.test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split sentences into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers in data:  630\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "label_id = []\n",
    "label_gen = []\n",
    "label_dem = []\n",
    "for p in range(len(train.people)):\n",
    "    count = 0\n",
    "    for s in range(len(train.person_by_index(p).sentences)):\n",
    "        sentence = train.person_by_index(p).sentence_by_index(s).raw_audio\n",
    "        data_set.append(sentence)\n",
    "        label_id.append(train.person_by_index(p).name)\n",
    "        label_gen.append(train.person_by_index(p).gender)\n",
    "        label_dem.append(train.person_by_index(p).region_name)\n",
    "for p in range(len(test.people)):\n",
    "    count = 0\n",
    "    for s in range(len(test.person_by_index(p).sentences)):\n",
    "        sentence = test.person_by_index(p).sentence_by_index(s).raw_audio\n",
    "        data_set.append(sentence)\n",
    "        label_id.append(test.person_by_index(p).name)\n",
    "        label_gen.append(test.person_by_index(p).gender)\n",
    "        label_dem.append(test.person_by_index(p).region_name)\n",
    "num_speakers = len(set(label_id))\n",
    "print('Number of speakers in data: ', num_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(label_id)\n",
    "label_id = le1.transform(label_id)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(label_gen)\n",
    "label_gen = le2.transform(label_gen)\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(label_dem)\n",
    "label_dem = le3.transform(label_dem)\n",
    "\n",
    "N = 20 # number of speakers being considered\n",
    "sub_data_set = []\n",
    "sub_label_id = []\n",
    "sub_label_gen = []\n",
    "sub_label_dem = []\n",
    "speak_ind = []\n",
    "S = [120,439,531,191,481,179,309,201,33,90,602,200,6,451,444,337,466,599,214,611]\n",
    "for ind1 in range(N):\n",
    "    ind2 = S[ind1]\n",
    "    while ind2 in speak_ind is False:\n",
    "        ind2 = np.random.randint(630, size=1)\n",
    "    speak_ind.append(ind2)\n",
    "act_ind = []\n",
    "for ID in speak_ind:\n",
    "    act_ind= np.where(label_id == ID)\n",
    "    sub_data_set = sub_data_set+data_set[act_ind[0][0]:act_ind[0][-1]+1]\n",
    "    sub_label_id = sub_label_id+label_id[act_ind[0]].tolist()\n",
    "    sub_label_gen = sub_label_gen+label_gen[act_ind[0]].tolist()\n",
    "    sub_label_dem = sub_label_dem+label_dem[act_ind[0]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lengths = []\n",
    "for p in range(len(train.people)):\n",
    "    for s in range(len(train.person_by_index(p).sentences)):\n",
    "        sentence_lengths.append(len(train.person_by_index(p).sentence_by_index(s).raw_audio))\n",
    "for p in range(len(test.people)):\n",
    "    for s in range(len(test.person_by_index(p).sentences)):\n",
    "        sentence_lengths.append(len(test.person_by_index(p).sentence_by_index(s).raw_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "wlen = 0.02\n",
    "num_train_per_test = 3 # for every 3 training sentences, there is 1 testing sentence\n",
    "training_set = []\n",
    "training_label_id = []\n",
    "training_label_gen = []\n",
    "training_label_dem = []\n",
    "testing_set = []\n",
    "testing_label_id = []\n",
    "testing_label_gen = []\n",
    "testing_label_dem = []\n",
    "for ID in set(sub_label_id):\n",
    "    person_ind = [i for i, x in enumerate(sub_label_id) if x == ID]\n",
    "    for i, sent_per_ID in enumerate(person_ind):\n",
    "        if i%(num_train_per_test+1) == 0:\n",
    "            testing_set.append(sub_data_set[sent_per_ID])\n",
    "            testing_label_id.append(sub_label_id[sent_per_ID])\n",
    "            testing_label_gen.append(sub_label_gen[sent_per_ID])\n",
    "            testing_label_dem.append(sub_label_dem[sent_per_ID])\n",
    "        else:\n",
    "            training_set.append(sub_data_set[sent_per_ID])\n",
    "            training_label_id.append(sub_label_id[sent_per_ID])\n",
    "            training_label_gen.append(sub_label_gen[sent_per_ID])\n",
    "            training_label_dem.append(sub_label_dem[sent_per_ID])\n",
    "\n",
    "len_samps = 1 # length of samples in seconds\n",
    "ave_seconds_per_ID = sum(sentence_lengths)/(fs*len(sentence_lengths))*10\n",
    "num_samps_per_ID = round(ave_seconds_per_ID)*10\n",
    "num_samps_per_ID_test = round(num_samps_per_ID*(1/(num_train_per_test+1)))\n",
    "num_samps_per_ID_train = num_samps_per_ID-num_samps_per_ID_test\n",
    "training_data = []\n",
    "training_l_id = []\n",
    "training_l_gen = []\n",
    "training_l_dem = []\n",
    "testing_data = []\n",
    "testing_l_id = []\n",
    "testing_l_gen = []\n",
    "testing_l_dem = []\n",
    "for ID_i, ID in enumerate(set(sub_label_id)):\n",
    "    train_person_ind = [i for i, x in enumerate(training_label_id) if x == ID]\n",
    "    test_person_ind = [i for i, x in enumerate(testing_label_id) if x == ID]\n",
    "    for samp in range(num_samps_per_ID_train):\n",
    "        sent = random.choice(train_person_ind)\n",
    "        while len(training_set[sent]) < round(fs*len_samps):\n",
    "            sent = random.choice(train_person_ind)\n",
    "        start_i = random.randint(0,len(training_set[sent])-round(fs*len_samps))\n",
    "        training_data.append(training_set[sent][start_i:start_i+round(fs*len_samps)])\n",
    "        training_l_id.append(ID_i)\n",
    "        training_l_gen.append(training_label_gen[sent])\n",
    "        training_l_dem.append(training_label_dem[sent])\n",
    "    for samp in range(num_samps_per_ID_test):\n",
    "        sent = random.choice(test_person_ind)\n",
    "        while len(testing_set[sent]) < round(fs*len_samps):\n",
    "            sent = random.choice(test_person_ind)\n",
    "        start_i = random.randint(0,len(testing_set[sent])-round(fs*len_samps))\n",
    "        testing_data.append(testing_set[sent][start_i:start_i+round(fs*len_samps)])\n",
    "        testing_l_id.append(ID_i)\n",
    "        testing_l_gen.append(testing_label_gen[sent])\n",
    "        testing_l_dem.append(testing_label_dem[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_filterbank(data,fs,wlen,nfilt):\n",
    "    logfbank_es = logfbank(data,samplerate=fs,winlen=wlen,nfilt=nfilt)\n",
    "    logfbank_es = (logfbank_es-np.mean(logfbank_es))/np.std(logfbank_es)\n",
    "    return logfbank_es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,hidden_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=hidden_channels,out_channels=hidden_channels,kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_channels,out_channels=hidden_channels, kernel_size=3, stride=1,padding=1,bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        y = F.leaky_relu(y,0)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = F.leaky_relu(y+x,0)\n",
    "        return y\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,in_channels,hidden_channels,num_speakers,num_regions):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,out_channels=hidden_channels,kernel_size=5,stride=2,padding=0,bias=True)\n",
    "        self.resblock = ResBlock(hidden_channels)\n",
    "        self.fc = nn.Linear(in_features=hidden_channels*24*15,out_features=num_speakers)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_channels*24*15,out_features=2)\n",
    "        self.fc3 = nn.Linear(in_features=hidden_channels*24*15,out_features=num_regions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x),0)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.resblock(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        y1 = self.fc(x)\n",
    "        y2 = self.fc2(x)\n",
    "        y3 = self.fc3(x)\n",
    "        return y1, y2, y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer, epoch):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    model.double()\n",
    "    for batch_idx, (data, target1, target2, target3) in enumerate(train_loader):\n",
    "        data, target1, target2, target3=data.to(device), target1.to(device), target2.to(device), target3.to(device)\n",
    "        data = data.reshape(len(data),1,data[0].size()[0],data[0].size()[1])\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2, output3 = model(data)\n",
    "        loss = (0.9*criterion(output1, target1))+(0.05*criterion(output2, target2))+(0.05*criterion(output3, target3)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        if batch_idx % (len(train_loader)//2) == 0:\n",
    "            print('Train({})[{:.0f}%]: Loss: {:.4f}'.format(\n",
    "                epoch, 100. * batch_idx / len(train_loader), train_loss/(batch_idx+1)))\n",
    "    loss = train_loss\n",
    "    return loss\n",
    "\n",
    "def test(model, device, test_loader, criterion, epoch):\n",
    "    model.eval()\n",
    "    model.double()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target1, target2, target3 in test_loader:\n",
    "            data, target1, target2, target3=data.to(device), target1.to(device), target2.to(device), target3.to(device)\n",
    "            data = data.reshape(len(data),1,data[0].size()[0],data[0].size()[1])\n",
    "            output1, output2, output3 = model(data)\n",
    "            test_loss += criterion(output1, target1).item() # sum up batch loss\n",
    "            pred = output1.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target1.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss = (test_loss*batch_size)/len(test_loader.dataset)\n",
    "    print('Test({}): Loss: {:.4f}, Accuracy: {:.4f}%'.format(\n",
    "        epoch, test_loss, 100. * correct / len(test_loader.dataset)))\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    loss = test_loss\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(optimizer_name, model, **kwargs):\n",
    "    if optimizer_name=='Adam':\n",
    "        optimizer = optim.Adam(model.parameters(),lr=kwargs['lr'])\n",
    "    elif optimizer_name=='SGD':\n",
    "        optimizer = optim.SGD(model.parameters(),lr=kwargs['lr'],momentum=kwargs['momentum'], weight_decay=kwargs['weight_decay'],nesterov=True)\n",
    "    else:\n",
    "        raise ValueError('Not valid optimizer name')\n",
    "    return optimizer\n",
    "    \n",
    "def make_scheduler(scheduler_name, optimizer, **kwargs):\n",
    "    if scheduler_name=='MultiStepLR':\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer,milestones=kwargs['milestones'],gamma=kwargs['factor'])\n",
    "    else:\n",
    "        raise ValueError('Not valid scheduler name')\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff Frequency is 0.\n",
      "Done with calculating spectrograms.\n",
      "Train(1)[0%]: Loss: 3.0315\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-780639ef9cf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mscheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_scheduler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheduler_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmilestones\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mtr_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mte_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mperf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-a936550e5290>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, device, train_loader, criterion, optimizer, epoch)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0moutput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cf_array = [0,10,100,200,500,1000,2000,3000,4000,5000,6000,7000]\n",
    "performances = []\n",
    "test_losses = []\n",
    "train_losses = []\n",
    "for cf in cf_array:\n",
    "    perf = []\n",
    "    tr_losses = []\n",
    "    te_losses = []\n",
    "    print('Cutoff Frequency is {}.'.format(cf))\n",
    "    batch_size = 5\n",
    "    train_loader,test_loader = {},{}\n",
    "    train_list = []\n",
    "    for ind, data in enumerate(training_data):\n",
    "        if cf == 0:\n",
    "            d = training_data[ind]\n",
    "        else:\n",
    "            sos = butter(10, cf/(fs/2), btype='hp', analog=False, output='sos')\n",
    "            d = sosfilt(sos,training_data[ind])\n",
    "        data = get_filterbank(d,fs,wlen,64)\n",
    "        train_list.append((data, training_l_id[ind], training_l_gen[ind], training_l_dem[ind]))\n",
    "    test_list = []\n",
    "    for ind, data in enumerate(testing_data):\n",
    "        if cf == 0:\n",
    "            d = testing_data[ind]\n",
    "        else:\n",
    "            sos = butter(10, cf/(fs/2), btype='hp', analog=False, output='sos')\n",
    "            d = sosfilt(sos,testing_data[ind])\n",
    "        data = get_filterbank(d,fs,wlen,64)\n",
    "        test_list.append((data, testing_l_id[ind], testing_l_gen[ind], testing_l_dem[ind]))\n",
    "    train_loader['timit'] = torch.utils.data.DataLoader(train_list, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader['timit'] = torch.utils.data.DataLoader(test_list, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    print('Done with calculating spectrograms.')\n",
    "\n",
    "    seed = 1\n",
    "    device = 'cpu'\n",
    "    data_name = 'timit'\n",
    "    optimizer_name = 'SGD'\n",
    "    scheduler_name = 'MultiStepLR'\n",
    "    num_epochs = 6\n",
    "    lr = 0.005\n",
    "    device = torch.device(device)\n",
    "    torch.manual_seed(1)\n",
    "    in_channels = 1\n",
    "    out_channels = N\n",
    "    model = ResNet(in_channels, out_channels, 20, 8).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = make_optimizer(optimizer_name, model, lr=lr, momentum=0.5, weight_decay=0)\n",
    "    scheduler = make_scheduler(scheduler_name, optimizer, milestones=[5,10,15], factor=0.1)\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        tr_l = train(model, device, train_loader[data_name], criterion, optimizer, epoch)\n",
    "        te_acc, te_l = test(model, device, test_loader[data_name], criterion, epoch)\n",
    "        perf.append(te_acc)\n",
    "        tr_losses.append(tr_l)\n",
    "        te_losses.append(te_l)\n",
    "        scheduler.step()\n",
    "        print('Optimizer Learning rate: {0:.4f}'.format(optimizer.param_groups[0]['lr']))\n",
    "    performances.append(perf)\n",
    "    train_losses.append(tr_losses)\n",
    "    test_losses.append(te_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(performances)):\n",
    "    plt.plot(performances[i])\n",
    "plt.show\n",
    "plt.title('Testing Accuracy for LPF Audio w/ Various Cutoff Frequencies')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Testing Accuracy [%]')\n",
    "plt.legend(['None', '100Hz', '200Hz','500Hz','1000Hz','2000Hz','3000Hz','4000Hz','None'])\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "from scipy.io.wavfile import write\n",
    "b, a = butter(10, 2000/(fs/2), btype='low', analog=False)\n",
    "d = lfilter(b,a,testing_data[0])\n",
    "scaled = np.int16(d/np.max(np.abs(data)) * 32767)\n",
    "write('audio.wav', 16000, scaled)\n",
    "winsound.PlaySound('audio.wav', winsound.SND_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
