{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<timit_utils.core.SubCorpus at 0x27dbd7ba898>,\n",
       " <timit_utils.core.SubCorpus at 0x27dbd7bab00>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n",
    "import timit_utils as tu\n",
    "import timit_utils.audio_utils as au\n",
    "import timit_utils.drawing_utils as du\n",
    "import librosa\n",
    "import pywt\n",
    "import random\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "from scipy.signal import butter, lfilter\n",
    "import speech_recognition as sr\n",
    "import re\n",
    "\n",
    "corpus = tu.Corpus('TIMIT')\n",
    "train = corpus.train\n",
    "test = corpus.test\n",
    "corpus.train, corpus.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = []\n",
    "label_id = []\n",
    "for p in range(len(train.people)):\n",
    "    count = 0\n",
    "    for s in range(len(train.person_by_index(p).sentences)):\n",
    "        sentence = train.person_by_index(p).sentence_by_index(s)\n",
    "        label_id.append(train.person_by_index(p).name)\n",
    "        data_set.append(sentence)\n",
    "for p in range(len(test.people)):\n",
    "    count = 0\n",
    "    for s in range(len(test.person_by_index(p).sentences)):\n",
    "        sentence = test.person_by_index(p).sentence_by_index(s)\n",
    "        label_id.append(test.person_by_index(p).name)\n",
    "        data_set.append(sentence)\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(label_id)\n",
    "label_id = le1.transform(label_id)\n",
    "N = 20 # number of speakers being considered\n",
    "sub_data_set = []\n",
    "speak_ind = []\n",
    "S = [120,439,531,191,481,179,309,201,33,90,602,200,6,451,444,337,466,599,214,611]\n",
    "for ind1 in range(N):\n",
    "    ind2 = S[ind1]\n",
    "    speak_ind.append(ind2)\n",
    "act_ind = []\n",
    "for ID in speak_ind:\n",
    "    act_ind= np.where(label_id == ID)\n",
    "    sub_data_set = sub_data_set+data_set[act_ind[0][0]:act_ind[0][-1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 2, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 1, 0, 0, 1, 3, 1, 4, 3, 2, 0, 0, 3, 0, 4, 0, 2, 2, 1, 2, 0, 2, 0, 0, 1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 2, 1, 3, 2, 0, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 2, 1, 0, 1, 4, 0, 1, 3, 4, 2, 0, 1, 0, 1, 5, 2, 0, 2, 0, 1, 1, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 2, 3, 1, 1, 0, 2, 0, 1, 2, 0, 1, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 3, 3, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 1, 2, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 2]\n",
      "[11, 9, 12, 13, 5, 6, 7, 5, 9, 6, 11, 9, 9, 11, 12, 7, 8, 6, 4, 13, 11, 9, 10, 6, 2, 7, 5, 9, 11, 3, 11, 6, 5, 3, 10, 7, 5, 12, 6, 6, 11, 9, 8, 6, 12, 7, 6, 8, 10, 8, 11, 9, 10, 8, 7, 8, 11, 8, 7, 6, 10, 9, 6, 16, 5, 7, 7, 4, 7, 5, 11, 9, 9, 5, 13, 7, 5, 8, 5, 8, 11, 9, 8, 11, 7, 6, 7, 10, 6, 6, 11, 9, 14, 6, 5, 8, 7, 4, 9, 6, 11, 9, 2, 6, 13, 5, 2, 5, 10, 8, 11, 9, 7, 7, 7, 5, 5, 11, 7, 5, 11, 9, 14, 6, 7, 7, 7, 12, 5, 4, 11, 9, 7, 7, 4, 7, 6, 8, 11, 4, 11, 9, 11, 15, 3, 6, 5, 7, 8, 4, 11, 9, 6, 7, 11, 12, 8, 5, 6, 6, 11, 9, 8, 4, 13, 4, 6, 9, 9, 10, 11, 9, 5, 16, 2, 9, 6, 7, 10, 4, 11, 9, 8, 8, 13, 5, 4, 6, 4, 8, 11, 9, 8, 8, 11, 8, 11, 7, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "wrongs = []\n",
    "corrects = []\n",
    "for s0 in sub_data_set:\n",
    "    sentence_w = s0.words_df.index.values\n",
    "    sentence_a = s0.raw_audio\n",
    "    sentence_a = np.int16(sentence_a*0.3*32767)\n",
    "    scipy.io.wavfile.write('temp.wav', 16000, sentence_a)\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile('temp.wav') as source:\n",
    "        audio = r.record(source)  # read the entire audio file\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  r.recognize_google(audio)).lower().split()\n",
    "    wrong = 0\n",
    "    correct = 0\n",
    "    for word in sentence_w:\n",
    "        if word in wordList:\n",
    "            correct = correct+1\n",
    "        else:\n",
    "            wrong = wrong+1\n",
    "    wrongs = wrongs+[wrong]\n",
    "    corrects = corrects+[correct]\n",
    "print(wrongs)\n",
    "print(corrects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "1586\n",
      "0.9047347404449515\n"
     ]
    }
   ],
   "source": [
    "print(sum(wrongs))\n",
    "print(sum(corrects))\n",
    "print(sum(corrects)/(sum(corrects)+sum(wrongs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(wrongs.count(0))\n",
    "print(wrongs.count(0)/(N*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
