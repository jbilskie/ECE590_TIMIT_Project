{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<timit_utils.core.SubCorpus at 0x10c731550>,\n",
       " <timit_utils.core.SubCorpus at 0x1c2920bdd8>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "import timit_utils as tu\n",
    "import timit_utils.audio_utils as au\n",
    "import timit_utils.drawing_utils as du\n",
    "import librosa\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "from sklearn.metrics import pairwise as pw\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "corpus = tu.Corpus('TIMIT')\n",
    "train = corpus.train\n",
    "test = corpus.test\n",
    "corpus.train, corpus.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel-scale Based Features for Speaker ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of speakers in data:  233\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "label_id = []\n",
    "label_gen = []\n",
    "label_dem = []\n",
    "num_regions = 3 # Number of regions to sample from\n",
    "# Train and test speakers come from the same 8 regions\n",
    "all_speaker_regions = list(train.regions.keys())\n",
    "speaker_regions = [all_speaker_regions[i] for i in np.random.choice(len(all_speaker_regions), replace=False, size=num_regions)]\n",
    "\n",
    "for p in range(len(train.people)):\n",
    "    count = 0\n",
    "    # Only draw speakers from certain regions\n",
    "    if train.person_by_index(p).region_name in speaker_regions:\n",
    "        for s in range(len(train.person_by_index(p).sentences)):\n",
    "            sentence = train.person_by_index(p).sentence_by_index(s).raw_audio\n",
    "            data_set.append(sentence)\n",
    "            label_id.append(train.person_by_index(p).name)\n",
    "            label_gen.append(train.person_by_index(p).gender)\n",
    "            label_dem.append(train.person_by_index(p).region_name)\n",
    "for p in range(len(test.people)):\n",
    "    count = 0\n",
    "    if test.person_by_index(p).region_name in speaker_regions:\n",
    "        for s in range(len(test.person_by_index(p).sentences)):\n",
    "            sentence = test.person_by_index(p).sentence_by_index(s).raw_audio\n",
    "            data_set.append(sentence)\n",
    "            label_id.append(test.person_by_index(p).name)\n",
    "            label_gen.append(test.person_by_index(p).gender)\n",
    "            label_dem.append(test.person_by_index(p).region_name)\n",
    "speakers_in_dataset = len(set(label_id))\n",
    "print('Number of speakers in data: ', speakers_in_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(label_id)\n",
    "label_id = le1.transform(label_id)\n",
    "le2 = preprocessing.LabelEncoder()\n",
    "le2.fit(label_gen)\n",
    "label_gen = le2.transform(label_gen)\n",
    "le3 = preprocessing.LabelEncoder()\n",
    "le3.fit(label_dem)\n",
    "label_dem = le3.transform(label_dem)\n",
    "\n",
    "num_speakers = 20 # number of speakers being considered\n",
    "\n",
    "sub_data_set = []\n",
    "sub_label_id = []\n",
    "sub_label_gen = []\n",
    "sub_label_dem = []\n",
    "speak_ind = []\n",
    "for ind1 in range(num_speakers):\n",
    "    ind2 = np.random.randint(speakers_in_dataset, size=1)\n",
    "    while ind2[0] in speak_ind: # Don't repeat speakers\n",
    "        ind2 = np.random.randint(speakers_in_dataset, size=1)\n",
    "    speak_ind.append(ind2[0])\n",
    "act_ind = []\n",
    "for ID in speak_ind:\n",
    "    act_ind= np.where(label_id == ID)\n",
    "    sub_data_set = sub_data_set+data_set[act_ind[0][0]:act_ind[0][-1]+1]\n",
    "    sub_label_id = sub_label_id+label_id[act_ind[0]].tolist()\n",
    "    sub_label_gen = sub_label_gen+label_gen[act_ind[0]].tolist()\n",
    "    sub_label_dem = sub_label_dem+label_dem[act_ind[0]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_lengths = []\n",
    "for p in range(len(train.people)):\n",
    "    for s in range(len(train.person_by_index(p).sentences)):\n",
    "        sentence_lengths.append(len(train.person_by_index(p).sentence_by_index(s).raw_audio))\n",
    "for p in range(len(test.people)):\n",
    "    for s in range(len(test.person_by_index(p).sentences)):\n",
    "        sentence_lengths.append(len(test.person_by_index(p).sentence_by_index(s).raw_audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filterbank(data,fs,wlen,nfilt):\n",
    "    # 64-dimensional filterbank coefficients\n",
    "    logfbank_es = logfbank(data,samplerate=fs,winlen=wlen,nfilt=64)\n",
    "    # ZMUV the filterbank coefficients\n",
    "    logfbank_es = (logfbank_es-np.mean(logfbank_es))/np.std(logfbank_es)\n",
    "    return logfbank_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fs = 16000\n",
    "wlen = 0.025\n",
    "num_train_per_test = 3 # for every 3 training sentences, there is 1 testing sentence\n",
    "training_set = []\n",
    "training_label_id = []\n",
    "training_label_gen = []\n",
    "training_label_dem = []\n",
    "testing_set = []\n",
    "testing_label_id = []\n",
    "testing_label_gen = []\n",
    "testing_label_dem = []\n",
    "for ID in set(sub_label_id):\n",
    "    person_ind = [i for i, x in enumerate(sub_label_id) if x == ID]\n",
    "    for i, sent_per_ID in enumerate(person_ind):\n",
    "        if i%(num_train_per_test+1) == 0: # Add 25% of data to testing set\n",
    "            testing_set.append(sub_data_set[sent_per_ID])\n",
    "            testing_label_id.append(sub_label_id[sent_per_ID])\n",
    "            testing_label_gen.append(sub_label_gen[sent_per_ID])\n",
    "            testing_label_dem.append(sub_label_dem[sent_per_ID])\n",
    "        else: # Add 75% of data to training set\n",
    "            training_set.append(sub_data_set[sent_per_ID])\n",
    "            training_label_id.append(sub_label_id[sent_per_ID])\n",
    "            training_label_gen.append(sub_label_gen[sent_per_ID])\n",
    "            training_label_dem.append(sub_label_dem[sent_per_ID])\n",
    "\n",
    "# Extract features from \n",
    "len_samps = 1 # length of samples in seconds\n",
    "fs = 16000\n",
    "ave_seconds_per_ID = sum(sentence_lengths)/(fs*len(sentence_lengths))*10\n",
    "num_samps_per_ID = round(ave_seconds_per_ID)*4\n",
    "num_samps_per_ID_test = round(num_samps_per_ID*(1/(num_train_per_test+1)))\n",
    "num_samps_per_ID_train = num_samps_per_ID-num_samps_per_ID_test\n",
    "training_data = []\n",
    "training_l_id = []\n",
    "training_l_gen = []\n",
    "training_l_dem = []\n",
    "testing_data = []\n",
    "testing_l_id = []\n",
    "testing_l_gen = []\n",
    "testing_l_dem = []\n",
    "for ID_i, ID in enumerate(set(sub_label_id)):\n",
    "    train_person_ind = [i for i, x in enumerate(training_label_id) if x == ID]\n",
    "    test_person_ind = [i for i, x in enumerate(testing_label_id) if x == ID]\n",
    "    for samp in range(num_samps_per_ID_train):\n",
    "        sent = random.choice(train_person_ind)\n",
    "        while len(training_set[sent]) < round(fs*len_samps):\n",
    "            sent = random.choice(train_person_ind)\n",
    "        start_i = random.randint(0,len(training_set[sent])-round(fs*len_samps))\n",
    "        curr_data = training_set[sent][start_i:start_i+round(fs*len_samps)]\n",
    "        training_data.append(get_filterbank(curr_data,fs,wlen,64))\n",
    "        training_l_id.append(ID_i)\n",
    "        training_l_gen.append(training_label_gen[sent])\n",
    "        training_l_dem.append(training_label_dem[sent])\n",
    "    for samp in range(num_samps_per_ID_test):\n",
    "        sent = random.choice(test_person_ind)\n",
    "        while len(testing_set[sent]) < round(fs*len_samps):\n",
    "            sent = random.choice(test_person_ind)\n",
    "        start_i = random.randint(0,len(testing_set[sent])-round(fs*len_samps))\n",
    "        curr_data = testing_set[sent][start_i:start_i+round(fs*len_samps)]\n",
    "        testing_data.append(get_filterbank(curr_data,fs,wlen,64))\n",
    "        testing_l_id.append(ID_i)\n",
    "        testing_l_gen.append(testing_label_gen[sent])\n",
    "        testing_l_dem.append(testing_label_dem[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,hidden_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=hidden_channels,out_channels=hidden_channels,kernel_size=3,stride=1,padding=1,bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_channels,out_channels=hidden_channels, kernel_size=3, stride=1,padding=1,bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        ##y = F.batch_norm(y,self.running_mu1,self.running_std1)\n",
    "        y = self.bn1(y)\n",
    "        y = F.leaky_relu(y,0.1)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        y = F.leaky_relu(y+x,0.1)\n",
    "        return y\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self,in_channels,hidden_channels,num_speakers,num_regions):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels,out_channels=hidden_channels,kernel_size=5,stride=2,padding=0,bias=True)\n",
    "        self.resblock = ResBlock(hidden_channels)\n",
    "        self.fc = nn.Linear(in_features=hidden_channels*24*15,out_features=num_speakers)\n",
    "        self.fc2 = nn.Linear(in_features=hidden_channels*24*15,out_features=2)\n",
    "        self.fc3 = nn.Linear(in_features=hidden_channels*24*15,out_features=num_regions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x),0.1)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.resblock(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        # Separate fully connected layers\n",
    "        y1 = self.fc(x)\n",
    "        y2 = self.fc2(x)\n",
    "        y3 = self.fc3(x)\n",
    "        return y1, y2, y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "for ind, data in enumerate(training_data):\n",
    "    train_list.append((data, training_l_id[ind], training_l_gen[ind], training_l_dem[ind]))\n",
    "test_list = []\n",
    "for ind, data in enumerate(testing_data):\n",
    "    test_list.append((data, testing_l_id[ind], testing_l_gen[ind], testing_l_dem[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 50. Epoch 1: Loss: 0.105452\n",
      "Batch size: 50. Epoch 2: Loss: 0.052094\n",
      "Batch size: 50. Epoch 3: Loss: 0.025415\n",
      "Batch size: 50. Epoch 4: Loss: 0.007734\n",
      "Batch size: 50. Epoch 5: Loss: 0.004706\n",
      "Batch size: 50. Epoch 6: Loss: 0.003488\n",
      "Batch size: 50. Epoch 7: Loss: 0.002856\n",
      "Batch size: 50. Epoch 8: Loss: 0.002360\n",
      "Batch size: 50. Epoch 9: Loss: 0.002075\n",
      "Batch size: 50. Epoch 10: Loss: 0.001818\n",
      "Testing accuracy: 80.16%\n",
      "Batch size: 50. Epoch 1: Loss: 0.092532\n",
      "Batch size: 50. Epoch 2: Loss: 0.042852\n",
      "Batch size: 50. Epoch 3: Loss: 0.021655\n"
     ]
    }
   ],
   "source": [
    "#batch_sizes = [5,25,50,100]\n",
    "test_accs = []\n",
    "num_epochs = 10\n",
    "test_loader = torch.utils.data.DataLoader(test_list, batch_size=len(test_list), shuffle=True, num_workers=0)\n",
    "#for batch_size in batch_sizes:\n",
    "    #batch_test_acc = []\n",
    "batch_size = 50\n",
    "# 5 runs\n",
    "for i in range(5):\n",
    "    train_loader = torch.utils.data.DataLoader(train_list, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    model = ResNet(1,64,num_speakers,num_regions)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    crit2 = nn.CrossEntropyLoss()\n",
    "    crit3 = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    # Train\n",
    "    epoch_losses = []\n",
    "    for i in range(num_epochs):\n",
    "        model.train(True)\n",
    "        epoch_loss = 0\n",
    "        for batch_id, (data,speakers,genders,regions) in enumerate(train_loader):\n",
    "            data = data.unsqueeze(1).float()\n",
    "            optimizer.zero_grad()\n",
    "            #Multi-task learning: simultaneously train on speaker identity, gender, and region labels\n",
    "            y1, y2, y3 = model(data)\n",
    "            #y2_pred = torch.argmax(y2,axis=1).float()\n",
    "            loss = 0.8*crit(y1,speakers) + 0.1*crit2(y2,genders) + 0.1*crit3(y3,regions)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        epoch_losses.append(epoch_loss/(len(train_list)+1))\n",
    "        print('Batch size: {}. Epoch {}: Loss: {:.6f}'.format(batch_size, i+1, epoch_losses[-1]))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.train(False)\n",
    "        # Test on entire testing set\n",
    "        for _, (data,speakers,genders,regions) in enumerate(test_loader):\n",
    "            data = data.unsqueeze(1).float()\n",
    "            y_hat, y2, y3 = model(data)\n",
    "            y_pred = torch.argmax(y_hat,axis=1)\n",
    "            corr_preds = torch.zeros(len(speakers),1)\n",
    "            corr_preds[y_pred == speakers] = 1\n",
    "            curr_test_acc = corr_preds.sum()/len(speakers)*100\n",
    "            print('Testing accuracy: {:.2f}%'.format(curr_test_acc))\n",
    "    test_accs.append(curr_test_acc.item())\n",
    "    #test_accs.append(batch_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions to true labels\n",
    "df = pd.DataFrame(data={'Predictions': y_pred, 'True labels': speakers})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Effect of batch size on testing accuracy at 10 epochs')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch_size,np.mean(test_accs,axis=1),'x')\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Testing accuracy (%)')\n",
    "plt.title('Effect of batch size on testing accuracy at 10 epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
