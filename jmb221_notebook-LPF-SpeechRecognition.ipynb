{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<timit_utils.core.SubCorpus at 0x1acdf3483c8>,\n",
       " <timit_utils.core.SubCorpus at 0x1ace90821d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "import scipy\n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n",
    "import timit_utils as tu\n",
    "import timit_utils.audio_utils as au\n",
    "import timit_utils.drawing_utils as du\n",
    "import librosa\n",
    "import pywt\n",
    "import random\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "from scipy.signal import butter, lfilter\n",
    "import speech_recognition as sr\n",
    "import re\n",
    "\n",
    "corpus = tu.Corpus('TIMIT')\n",
    "train = corpus.train\n",
    "test = corpus.test\n",
    "corpus.train, corpus.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = []\n",
    "label_id = []\n",
    "for p in range(len(train.people)):\n",
    "    count = 0\n",
    "    for s in range(len(train.person_by_index(p).sentences)):\n",
    "        sentence = train.person_by_index(p).sentence_by_index(s)\n",
    "        label_id.append(train.person_by_index(p).name)\n",
    "        data_set.append(sentence)\n",
    "for p in range(len(test.people)):\n",
    "    count = 0\n",
    "    for s in range(len(test.person_by_index(p).sentences)):\n",
    "        sentence = test.person_by_index(p).sentence_by_index(s)\n",
    "        label_id.append(test.person_by_index(p).name)\n",
    "        data_set.append(sentence)\n",
    "\n",
    "le1 = preprocessing.LabelEncoder()\n",
    "le1.fit(label_id)\n",
    "label_id = le1.transform(label_id)\n",
    "N = 20 # number of speakers being considered\n",
    "sub_data_set = []\n",
    "speak_ind = []\n",
    "S = [120,439,531,191,481,179,309,201,33,90,602,200,6,451,444,337,466,599,214,611]\n",
    "for ind1 in range(N):\n",
    "    ind2 = S[ind1]\n",
    "    speak_ind.append(ind2)\n",
    "act_ind = []\n",
    "for ID in speak_ind:\n",
    "    act_ind= np.where(label_id == ID)\n",
    "    sub_data_set = sub_data_set+data_set[act_ind[0][0]:act_ind[0][-1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff Frequency is 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jessi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff Frequency is 100.\n",
      "Cutoff Frequency is 200.\n",
      "Cutoff Frequency is 500.\n"
     ]
    }
   ],
   "source": [
    "cf_array = [10,100,200,500,1000,2000,3000,4000,5000,6000,7000,8000]\n",
    "w_performances = []\n",
    "s_performances = []\n",
    "for cf in cf_array:\n",
    "    print('Cutoff Frequency is {}.'.format(cf))\n",
    "    wrongs = []\n",
    "    corrects = []\n",
    "    for s0 in sub_data_set:\n",
    "        sentence_w = s0.words_df.index.values\n",
    "        sentence_a = s0.raw_audio\n",
    "        if cf == 8000:\n",
    "            d = sentence_a\n",
    "        else:\n",
    "            b, a = butter(10, cf/(16000/2), btype='low', analog=False)\n",
    "            d = lfilter(b,a,sentence_a)\n",
    "        sentence_a = np.int16(d*0.3*32767)\n",
    "        scipy.io.wavfile.write('temp.wav', 16000, sentence_a)\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile('temp.wav') as source:\n",
    "            audio = r.record(source)  # read the entire audio file\n",
    "        wordList = []\n",
    "        try:\n",
    "            words = r.recognize_google(audio)\n",
    "            wordList = re.sub(\"[^\\w]\", \" \",  words).lower().split()\n",
    "        except:\n",
    "            pass\n",
    "        wrong = 0\n",
    "        correct = 0\n",
    "        for word in sentence_w:\n",
    "            if word in wordList:\n",
    "                correct = correct+1\n",
    "            else:\n",
    "                wrong = wrong+1\n",
    "        wrongs = wrongs+[wrong]\n",
    "        corrects = corrects+[correct]\n",
    "    w_correct = sum(corrects)/(sum(corrects)+sum(wrongs))*100\n",
    "    s_correct = wrongs.count(0)/(N*10)*100\n",
    "    w_performances = w_performances + [w_correct]\n",
    "    s_performances = s_performances + [s_correct]\n",
    "print(w_performances)\n",
    "print(s_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
